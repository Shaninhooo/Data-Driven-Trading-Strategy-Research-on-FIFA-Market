{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "15cac467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "from data_scraping.db_utils import get_connection\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "982a1173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\441788012.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  cards_26_df = pd.read_sql(\"SELECT * FROM cards WHERE game = 26\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\441788012.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  cards_25_df = pd.read_sql(\"SELECT * FROM cards WHERE game = 25\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\441788012.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sales_26_df = pd.read_sql(\"SELECT * FROM market_sales\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\441788012.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  prices_25_df = pd.read_sql(\"SELECT * FROM price_history\", conn)\n"
     ]
    }
   ],
   "source": [
    "conn = get_connection()\n",
    "cards_26_df = pd.read_sql(\"SELECT * FROM cards WHERE game = 26\", conn)\n",
    "cards_25_df = pd.read_sql(\"SELECT * FROM cards WHERE game = 25\", conn)\n",
    "sales_26_df = pd.read_sql(\"SELECT * FROM market_sales\", conn)\n",
    "prices_25_df = pd.read_sql(\"SELECT * FROM price_history\", conn)\n",
    "\n",
    "df_26 = sales_26_df.merge(cards_26_df, on='card_id', how='left')\n",
    "df_25 = prices_25_df.merge(cards_25_df, on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67649e2d",
   "metadata": {},
   "source": [
    "### Cards Between FC 25 and FC 26 Similar Players Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2b6dacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\982070285.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  fifa25_prices_df = pd.read_sql(f\"\"\"\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\982070285.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  cards25_df = pd.read_sql(\"SELECT card_id, name FROM cards WHERE game=25\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name  price  last_price   pct_diff\n",
      "956                    jonathan tah   6015        7000  16.375727\n",
      "588                       ewa pajor  10969       12750  16.236667\n",
      "132             alexis mac allister   9107       10500  15.295926\n",
      "392                     luka modric   8308        9500  14.347617\n",
      "133             alexis mac allister   9269       10500  13.280829\n",
      "112                  victor osimhen  12610       14250  13.005551\n",
      "393                     luka modric   8923        9500   6.466435\n",
      "589                       ewa pajor  11977       12750   6.454037\n",
      "125               emiliano martinez  13915       14500   4.204096\n",
      "461           debora c. de oliveira  27635       28750   4.034739\n",
      "328                     chloe kelly   8576        8900   3.777985\n",
      "214                    paulo dybala  25578       26000   1.649855\n",
      "681                  josko gvardiol   7682        7800   1.536058\n",
      "866                     yann sommer   9911       10000   0.897992\n",
      "1067              randal kolo muani   9956       10000   0.441945\n",
      "957                    jonathan tah   7041        7000  -0.582304\n",
      "867                     yann sommer  10076       10000  -0.754268\n",
      "460           debora c. de oliveira  29306       28750  -1.897222\n",
      "329                     chloe kelly   9229        8900  -3.564850\n",
      "312                     lauren hemp  11958       11000  -8.011373\n",
      "369                     selma bacha  23609       21000 -11.050870\n",
      "512                     guro reiten  15557       13750 -11.615350\n",
      "94    bruno miguel borges fernandes  15401       13500 -12.343354\n",
      "86                      declan rice  19974       17500 -12.386102\n",
      "87                      declan rice  20366       17500 -14.072474\n",
      "410           daniel carvajal ramos   6656        5700 -14.362981\n",
      "368                     selma bacha  24977       21000 -15.922649\n",
      "313                     lauren hemp  13145       11000 -16.317992\n",
      "215                    paulo dybala  31653       26000 -17.859287\n",
      "846              alessandro bastoni  24701       20250 -18.019513\n",
      "1066              randal kolo muani  12208       10000 -18.086501\n",
      "450             unai simon mendibil   8396        6800 -19.009052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\982070285.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  cards26_df = pd.read_sql(\"SELECT card_id, name FROM cards WHERE game=26\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Keep only name and price from last FIFA\n",
    "date_target = '2024-09-23 23:59:59' \n",
    "\n",
    "fifa25_prices_df = pd.read_sql(f\"\"\"\n",
    "    SELECT ph.card_id,\n",
    "           COALESCE(ph.pc_value, ph.console_value) AS price\n",
    "    FROM price_history ph\n",
    "    JOIN (\n",
    "        SELECT card_id, MAX(date_time) AS max_dt\n",
    "        FROM price_history\n",
    "        WHERE date_time <= '{date_target}'\n",
    "          AND (pc_value > 0 OR console_value > 0)\n",
    "        GROUP BY card_id\n",
    "    ) sub\n",
    "    ON ph.card_id = sub.card_id AND ph.date_time = sub.max_dt\n",
    "\"\"\", conn)\n",
    "\n",
    "# Merge card names\n",
    "cards25_df = pd.read_sql(\"SELECT card_id, name FROM cards WHERE game=25\", conn)\n",
    "fifa25_prices_df = fifa25_prices_df.merge(cards25_df, on='card_id', how='left')\n",
    "\n",
    "# --- Get last sold price per card in FIFA 26 ---\n",
    "fifa26_last_price = (sales_26_df[sales_26_df['sold_price'] > 0]   # only valid sales\n",
    "                     .sort_values(['card_id','sale_time'])\n",
    "                     .groupby('card_id')\n",
    "                     .agg(last_price=('sold_price','last'))   # last sold price\n",
    "                     .reset_index())\n",
    "\n",
    "# Merge card names\n",
    "cards26_df = pd.read_sql(\"SELECT card_id, name FROM cards WHERE game=26\", conn)\n",
    "fifa26_last_price = fifa26_last_price.merge(cards26_df, on='card_id', how='left')\n",
    "\n",
    "# Normalize names for merging\n",
    "fifa25_prices_df['name'] = fifa25_prices_df['name'].str.lower().str.strip()\n",
    "fifa26_last_price['name'] = fifa26_last_price['name'].str.lower().str.strip()\n",
    "\n",
    "# Merge FIFA 25 and FIFA 26 prices on name\n",
    "price_comparison = fifa25_prices_df.merge(\n",
    "    fifa26_last_price[['name','last_price']],\n",
    "    on='name',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Compute % difference\n",
    "price_comparison['pct_diff'] = ((price_comparison['last_price'] - price_comparison['price']) \n",
    "                                / price_comparison['price']) * 100\n",
    "\n",
    "# Filter similar prices Â±10%\n",
    "similar_prices = price_comparison[(price_comparison['pct_diff'].abs() <= 20) & (price_comparison['last_price'] > 5000) & (price_comparison['last_price'] < 30000)].sort_values('pct_diff', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "print(similar_prices[['name','price','last_price','pct_diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c30f1d",
   "metadata": {},
   "source": [
    "#### Meta Main League CB Prices Comparison (Over 80 Pace and 80 Defending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ebac8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\589323997.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pace_df = pd.read_sql(\"SELECT * FROM card_pace_stats\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\589323997.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  shooting_df = pd.read_sql(\"SELECT * FROM card_shooting_stats\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\589323997.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  passing_df = pd.read_sql(\"SELECT * FROM card_passing_stats\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\589323997.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dribbling_df = pd.read_sql(\"SELECT * FROM card_dribbling_stats\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\589323997.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  defending_df = pd.read_sql(\"SELECT * FROM card_defending_stats\", conn)\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_4304\\589323997.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  physical_df = pd.read_sql(\"SELECT * FROM card_physical_stats\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        card_id  pc_value  console_value           date_time  \\\n",
      "441723    33134   28493.0            NaN 2024-09-23 09:30:00   \n",
      "594563    43991   38942.0            NaN 2024-09-23 09:30:00   \n",
      "\n",
      "                                   name  game    version nationality  \\\n",
      "441723  Gleison Bremer Silva Nascimento  25.0  Gold Rare      Brazil   \n",
      "594563                    Fikayo Tomori  25.0  Gold Rare     England   \n",
      "\n",
      "             league       club  ... interceptions  heading_acc  def_aware  \\\n",
      "441723  Serie A TIM   Juventus  ...            84           87         87   \n",
      "594563  Serie A TIM  Milano FC  ...            84           83         84   \n",
      "\n",
      "        stand_tackle  slide_tackle physical_overall  jumping  stamina  \\\n",
      "441723            87            84               85       94       75   \n",
      "594563            87            81               80       92       71   \n",
      "\n",
      "        strength  aggression  \n",
      "441723        89          84  \n",
      "594563        81          88  \n",
      "\n",
      "[2 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load stats tables\n",
    "pace_df = pd.read_sql(\"SELECT * FROM card_pace_stats\", conn)\n",
    "shooting_df = pd.read_sql(\"SELECT * FROM card_shooting_stats\", conn)\n",
    "passing_df = pd.read_sql(\"SELECT * FROM card_passing_stats\", conn)\n",
    "dribbling_df = pd.read_sql(\"SELECT * FROM card_dribbling_stats\", conn)\n",
    "defending_df = pd.read_sql(\"SELECT * FROM card_defending_stats\", conn)\n",
    "physical_df = pd.read_sql(\"SELECT * FROM card_physical_stats\", conn)\n",
    "\n",
    "pace_df = pace_df.drop(columns=['id'], errors='ignore')\n",
    "shooting_df = shooting_df.drop(columns=['id'], errors='ignore')\n",
    "passing_df = passing_df.drop(columns=['id'], errors='ignore')\n",
    "dribbling_df = dribbling_df.drop(columns=['id'], errors='ignore')\n",
    "defending_df = defending_df.drop(columns=['id'], errors='ignore')\n",
    "physical_df = physical_df.drop(columns=['id'], errors='ignore')\n",
    "\n",
    "date_target = '2024-09-23 23:59:59' \n",
    "\n",
    "# Merge all stats with cards info\n",
    "full_stats_df = df_25.merge(pace_df, on=\"card_id\", how=\"left\") \\\n",
    "                        .merge(shooting_df, on=\"card_id\", how=\"left\") \\\n",
    "                        .merge(passing_df, on=\"card_id\", how=\"left\") \\\n",
    "                        .merge(dribbling_df, on=\"card_id\", how=\"left\") \\\n",
    "                        .merge(defending_df, on=\"card_id\", how=\"left\") \\\n",
    "                        .merge(physical_df, on=\"card_id\", how=\"left\")\n",
    "\n",
    "main_league_cb_26 = full_stats_df[\n",
    "    (\n",
    "        (full_stats_df[\"league\"] == \"Ligue 1 Uber Eats\")\n",
    "        | (full_stats_df[\"league\"] == \"Premier League\")\n",
    "        | (full_stats_df[\"league\"] == \"LALIGA EA SPORTS\")\n",
    "        | (full_stats_df[\"league\"] == \"Serie A TIM\")\n",
    "        | (full_stats_df[\"league\"] == \"Bundesliga\")\n",
    "    )\n",
    "    & (full_stats_df[\"position\"] == \"CB\")\n",
    "    & (full_stats_df[\"pace_overall\"] >= 80)\n",
    "    & (full_stats_df[\"defending_overall\"] >= 82)\n",
    "    & (full_stats_df[\"date_time\"] <= date_target)\n",
    "    & (full_stats_df[\"pc_value\"] >= 1000)\n",
    "    & (full_stats_df[\"pc_value\"] <= 40000)\n",
    "]\n",
    "\n",
    "print(main_league_cb_26)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ab60854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð¥ Potential Buy Candidates ð¥\n",
      "           name  last_10_avg  last_50_avg  drop_%  sales_volume  \\\n",
      "1   Lauren Hemp      12350.0     14016.67   11.89           424   \n",
      "0  Felix Nmecha       7860.0      8795.83   10.64           407   \n",
      "\n",
      "   suggested_buy  suggested_sell  potential_profit  \n",
      "1          11980           13736              1756  \n",
      "0           7624            8620               996  \n"
     ]
    }
   ],
   "source": [
    "# Filter recent data (last 24h)\n",
    "recent_df = df_26[(df_26['sale_time'] > df_26['sale_time'].max() - pd.Timedelta(hours=24)) \n",
    "                  & (df_26['sold_price'] > 6000) \n",
    "                  & (df_26['platform'] == \"pc\")]\n",
    "\n",
    "buy_candidates = []\n",
    "\n",
    "# Loop through each card\n",
    "for name, group in recent_df.groupby('name'):\n",
    "    group = group.sort_values('sale_time', ascending=False)\n",
    "    \n",
    "    if len(group) >= 50:  # need enough sales for comparison\n",
    "        last_short_avg = group.head(10)['sold_price'].mean()  # short-term average\n",
    "        last_long_avg = group.head(60)['sold_price'].mean()   # longer-term average\n",
    "\n",
    "        sales_volume = group.shape[0]\n",
    "\n",
    "        # Check drop & liquidity\n",
    "        if last_short_avg < 0.9 * last_long_avg and sales_volume >= 20:\n",
    "            buy_price = round(last_short_avg * 0.97)   # buy slightly below dip\n",
    "            sell_price = round(last_long_avg * 0.98)  # sell slightly below average\n",
    "\n",
    "            buy_candidates.append({\n",
    "                \"name\": name,\n",
    "                \"last_10_avg\": round(last_short_avg, 2),\n",
    "                \"last_50_avg\": round(last_long_avg, 2),\n",
    "                \"drop_%\": round((last_long_avg - last_short_avg) / last_long_avg * 100, 2),\n",
    "                \"sales_volume\": sales_volume,\n",
    "                \"suggested_buy\": buy_price,\n",
    "                \"suggested_sell\": sell_price,\n",
    "                \"potential_profit\": sell_price - buy_price\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "buy_df = pd.DataFrame(buy_candidates)\n",
    "\n",
    "if not buy_df.empty:\n",
    "    buy_df = buy_df.sort_values(\"drop_%\", ascending=False)\n",
    "    print(\"ð¥ Potential Buy Candidates ð¥\")\n",
    "    print(buy_df.head(20))\n",
    "else:\n",
    "    print(\"No buy candidates found with current filters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eca5b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð Stable Cards with Undercuts (Low Volatility Snipes) ð\n",
      "                                 name  avg_price  std_dev  volatility_%  \\\n",
      "11                      Fikayo Tomori    8783.50   320.77          3.65   \n",
      "8                         Declan Rice   17331.25   863.46          4.98   \n",
      "1                   Antoine Griezmann   17408.75   782.65          4.50   \n",
      "5                         Bukayo Saka   18966.25   800.71          4.22   \n",
      "6               David De Gea Quintana   12407.00   471.71          3.80   \n",
      "4                     Bradley Barcola    9089.00   417.19          4.59   \n",
      "2                     Antonio Rudiger   71162.50  2967.55          4.17   \n",
      "27              Rodrygo Silva de Goes   65027.50  2557.97          3.93   \n",
      "3                 Aurelien Tchouameni   15645.00   675.93          4.32   \n",
      "14                      Heung Min Son   12696.25   519.64          4.09   \n",
      "31                      Sandro Tonali   21675.00   889.64          4.10   \n",
      "7                     Dayot Upamecano   18953.75   816.01          4.31   \n",
      "23                     Nicolo Barella   36696.25  1726.22          4.70   \n",
      "29                   Ryan Gravenberch   83917.50  3681.33          4.39   \n",
      "26                 Robert Lewandowski    8588.00   320.73          3.73   \n",
      "18                     Julian Alvarez   76157.50  3785.91          4.97   \n",
      "24                         Phil Foden    9355.75   435.15          4.65   \n",
      "10                  Eduardo Camavinga   17670.00   577.40          3.27   \n",
      "25           Rafael da Conceicao Leao   77317.50  3059.78          3.96   \n",
      "30  Salma Celeste Paralluelo Ayingono   45861.25  2006.54          4.38   \n",
      "\n",
      "    lowest_sale  undercut_%  sales_volume  \n",
      "11         6700       23.72           200  \n",
      "8         13250       23.55           200  \n",
      "1         13500       22.45           200  \n",
      "5         15000       20.91           200  \n",
      "6          9900       20.21           200  \n",
      "4          7300       19.68           200  \n",
      "2         57500       19.20           200  \n",
      "27        53000       18.50           200  \n",
      "3         12750       18.50           200  \n",
      "14        10500       17.30           200  \n",
      "31        18250       15.80           200  \n",
      "7         16000       15.58           200  \n",
      "23        31000       15.52           200  \n",
      "29        71000       15.39           200  \n",
      "26         7300       15.00           200  \n",
      "18        65000       14.65           200  \n",
      "24         8000       14.49           200  \n",
      "10        15250       13.70           200  \n",
      "25        67000       13.34           200  \n",
      "30        39750       13.33           200  \n"
     ]
    }
   ],
   "source": [
    "# Filter last 24h of sales\n",
    "recent_df = df_26[(df_26['sale_time'] > df_26['sale_time'].max() - pd.Timedelta(hours=24)) \n",
    "                  & (df_26['sold_price'] > 6000) \n",
    "                  & (df_26['platform'] == \"pc\")]\n",
    "\n",
    "volatility_candidates = []\n",
    "\n",
    "# Loop through each card\n",
    "for name, group in recent_df.groupby('name'):\n",
    "    group = group.sort_values('sale_time', ascending=False)\n",
    "    \n",
    "    if len(group) >= 200:  # need enough sales to judge stability\n",
    "        last_200 = group.head(200)['sold_price']\n",
    "        avg_price = last_200.mean()\n",
    "        std_dev = last_200.std()\n",
    "        cv = std_dev / avg_price  # coefficient of variation (volatility measure)\n",
    "\n",
    "        # Look for stability (low volatility, e.g. <5%) \n",
    "        # and presence of dips (at least one sale <90% of avg)\n",
    "        if cv < 0.05 and (last_200.min() < 0.9 * avg_price):\n",
    "            volatility_candidates.append({\n",
    "                \"name\": name,\n",
    "                \"avg_price\": round(avg_price, 2),\n",
    "                \"std_dev\": round(std_dev, 2),\n",
    "                \"volatility_%\": round(cv * 100, 2),\n",
    "                \"lowest_sale\": last_200.min(),\n",
    "                \"undercut_%\": round((avg_price - last_200.min()) / avg_price * 100, 2),\n",
    "                \"sales_volume\": len(last_200)\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "vol_df = pd.DataFrame(volatility_candidates).sort_values(\"undercut_%\", ascending=False)\n",
    "\n",
    "print(\"ð Stable Cards with Undercuts (Low Volatility Snipes) ð\")\n",
    "print(vol_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6e10ddb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Combined BUY LIST generated!\n",
      "                         name  avg_price  std_dev  volatility_%  lowest_sale  \\\n",
      "0                Dean Huijsen     787.00    34.81          4.42        600.0   \n",
      "1               Fikayo Tomori    8783.50   320.77          3.65       6700.0   \n",
      "2                 Declan Rice   17331.25   863.46          4.98      13250.0   \n",
      "3           Antoine Griezmann   17408.75   782.65          4.50      13500.0   \n",
      "4                 Bukayo Saka   18966.25   800.71          4.22      15000.0   \n",
      "5       David De Gea Quintana   12407.00   471.71          3.80       9900.0   \n",
      "6             Bradley Barcola    9089.00   417.19          4.59       7300.0   \n",
      "7   Gabriel Fernando de Jesus     867.00    38.32          4.42        700.0   \n",
      "8             Antonio Rudiger   71162.50  2967.55          4.17      57500.0   \n",
      "9         Aurelien Tchouameni   15645.00   675.93          4.32      12750.0   \n",
      "10      Rodrygo Silva de Goes   65027.50  2557.97          3.93      53000.0   \n",
      "11              Heung Min Son   12696.25   519.64          4.09      10500.0   \n",
      "12             Federico Gatti     654.75    25.85          3.95        550.0   \n",
      "13              Sandro Tonali   21675.00   889.64          4.10      18250.0   \n",
      "14            Denzel Dumfries    4032.50   162.87          4.04       3400.0   \n",
      "15            Dayot Upamecano   18953.75   816.01          4.31      16000.0   \n",
      "16             Nicolo Barella   36696.25  1726.22          4.70      31000.0   \n",
      "17           Ryan Gravenberch   83917.50  3681.33          4.39      71000.0   \n",
      "18    Martin Zubimendi Ibanez     825.75    36.48          4.42        700.0   \n",
      "19               Noni Madueke     825.50    34.72          4.21        700.0   \n",
      "\n",
      "    undercut_%  sales_volume              strategy  last_10_avg  last_50_avg  \\\n",
      "0        23.76           200  Low-Volatility Snipe          NaN          NaN   \n",
      "1        23.72           200  Low-Volatility Snipe          NaN          NaN   \n",
      "2        23.55           200  Low-Volatility Snipe          NaN          NaN   \n",
      "3        22.45           200  Low-Volatility Snipe          NaN          NaN   \n",
      "4        20.91           200  Low-Volatility Snipe          NaN          NaN   \n",
      "5        20.21           200  Low-Volatility Snipe          NaN          NaN   \n",
      "6        19.68           200  Low-Volatility Snipe          NaN          NaN   \n",
      "7        19.26           200  Low-Volatility Snipe          NaN          NaN   \n",
      "8        19.20           200  Low-Volatility Snipe          NaN          NaN   \n",
      "9        18.50           200  Low-Volatility Snipe          NaN          NaN   \n",
      "10       18.50           200  Low-Volatility Snipe          NaN          NaN   \n",
      "11       17.30           200  Low-Volatility Snipe          NaN          NaN   \n",
      "12       16.00           200  Low-Volatility Snipe          NaN          NaN   \n",
      "13       15.80           200  Low-Volatility Snipe          NaN          NaN   \n",
      "14       15.69           200  Low-Volatility Snipe          NaN          NaN   \n",
      "15       15.58           200  Low-Volatility Snipe          NaN          NaN   \n",
      "16       15.52           200  Low-Volatility Snipe          NaN          NaN   \n",
      "17       15.39           200  Low-Volatility Snipe          NaN          NaN   \n",
      "18       15.23           200  Low-Volatility Snipe          NaN          NaN   \n",
      "19       15.20           200  Low-Volatility Snipe          NaN          NaN   \n",
      "\n",
      "    drop_%  suggested_buy  suggested_sell  potential_profit  \n",
      "0      NaN            NaN             NaN               NaN  \n",
      "1      NaN            NaN             NaN               NaN  \n",
      "2      NaN            NaN             NaN               NaN  \n",
      "3      NaN            NaN             NaN               NaN  \n",
      "4      NaN            NaN             NaN               NaN  \n",
      "5      NaN            NaN             NaN               NaN  \n",
      "6      NaN            NaN             NaN               NaN  \n",
      "7      NaN            NaN             NaN               NaN  \n",
      "8      NaN            NaN             NaN               NaN  \n",
      "9      NaN            NaN             NaN               NaN  \n",
      "10     NaN            NaN             NaN               NaN  \n",
      "11     NaN            NaN             NaN               NaN  \n",
      "12     NaN            NaN             NaN               NaN  \n",
      "13     NaN            NaN             NaN               NaN  \n",
      "14     NaN            NaN             NaN               NaN  \n",
      "15     NaN            NaN             NaN               NaN  \n",
      "16     NaN            NaN             NaN               NaN  \n",
      "17     NaN            NaN             NaN               NaN  \n",
      "18     NaN            NaN             NaN               NaN  \n",
      "19     NaN            NaN             NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "vol_df['strategy'] = 'Low-Volatility Snipe'\n",
    "buy_df['strategy'] = 'Momentum Crash'\n",
    "\n",
    "# --- Merge both datasets ---\n",
    "buy_list = pd.concat([vol_df, buy_df], ignore_index=True)\n",
    "\n",
    "# --- Optional: filter by key metrics ---\n",
    "# Example filters: volatility < 5% and undercut > 10%\n",
    "buy_list_filtered = buy_list[\n",
    "    (buy_list['volatility_%'] < 5) & \n",
    "    (buy_list['undercut_%'] > 10)\n",
    "]\n",
    "\n",
    "# --- Sort by potential profit (undercut % descending) ---\n",
    "buy_list_sorted = buy_list_filtered.sort_values(by='undercut_%', ascending=False)\n",
    "\n",
    "# --- Save the combined BUY LIST ---\n",
    "buy_list_sorted.to_csv(\"combined_buy_list.csv\", index=False)\n",
    "\n",
    "print(\"â Combined BUY LIST generated!\")\n",
    "print(buy_list_sorted.head(20))  # Preview top 20 cards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
